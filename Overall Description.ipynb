{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPMG Analysis with ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CPMG signal is anaylized with a machine learning model to extract out the hyperfine coeffcients of nuclei in a diamond.  \n",
    ": 2가지 측면에서 분석. Denoise와 Spin Detection을 목적으로 하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 왜 ML분석을 했는가?  \n",
    ": 기존에는 따로 분석할 수 있는 tool이 부재하였다.  \n",
    "<br/>\n",
    "* 왜 부재하였는가?  \n",
    ": CPMG 신호를 설명하는 이론적 기반은 있었지만,  \n",
    "  그 이론 수식을 활용하여 실험치에서 우리가 원하는 값(hyperfine coeffecients)을 유도하기란 어려웠다.  \n",
    "  특히 상온에서의 실험치는 Decoherence, Noise의 간섭이 심했기에 더 어려운 점이 많았다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 왜 원하는 값(hyperfine coeffecients)을 찾기가 어려운가?  \n",
    "  : 일단, CPMG신호가 ${}^{13}C$의 분포에 따라 어떻게 나오는지 살펴보자.  \n",
    "  1) diamond 내부에 ${}^{13}C$가 없고 오로지 NV center만 있다고 한다면, 그 때의 NV center 안의 전자 state는 다음과 같다.  \n",
    "  $$[Fig.1 \\;\\; px값이 \\;계속 \\;1로 \\;나오는 \\;그래프]$$\n",
    "  2) NV center가 상호작용하는 ${}^{13}C$가 1개 있다면, 그 때 얻어지는 전자 state은 다음과 같다.  \n",
    "  $$[Fig.2 \\;\\; px값이 \\;1개의 \\;주기를 \\;가진 \\;그래프]$$  \n",
    "  3) NV center가 상호작용하는 ${}^{13}C$가 2개 있다면, 그 때 얻어지는 전자 state은 다음과 같다.  \n",
    "  $$[Fig.2 \\;\\; px값이 \\;2개의\\; 주기를\\; 가진\\; 그래프]$$  \n",
    "즉, ${}^{13}C$ 1 개당 unique한 주기 1개 생긴다. 다시 말해서, hyperfine parameter(A,B) 하나의 pair 당 하나의 주기가 생긴다.  \n",
    "이러한 특성은 CPMG로 부터 Hyperfine Coefficients를 찾아내기 수월하게 만든다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그러나, 이런 장점을 활용하기 어렵게 만드는 어려운 점들도 있다.<br/><br/>\n",
    "\n",
    "    첫째, Diamond sample내에 NV center와 상호작용하는 ${}^{13}C$가 얼마나 많은지 사전에 알 수 없다. 그러므로 실험치가 주어졌을 때,  \n",
    "    $\\hspace{12mm}$그 실험치가 몇 개의 ${}^{13}C$와 상호작용한 결과인지 알 수 없다.  \n",
    "    $\\hspace{12mm}$따라서 이론 수식에 몇 개의 spin 값들을 넣어야 실험치를 설명할 수 있는지 알기 힘들다.  \n",
    "    둘째, 수식이 매우 복잡하다.  \n",
    "    $\\hspace{12mm}$이 계의 Hamiltonian으로부터 Fig.2의 ${}^{13}C$가 1개 있을 때 전자의 state를 표현하는 수식을 쓰면 다음과 같다. 참고문헌(Tim Taminiau)\n",
    "    $$수식-(1)$$\n",
    "    $\\hspace{12mm}$위의 수식에서 A,B가 ${}^{13}C$의 hyperfine coeffient이고, 이 수식들은 상호작용하는 핵스핀이 늘어날 때, 하나씩 계속 곱해진다.  \n",
    "    $\\hspace{12mm}$즉, 3개의 스핀이 있으면, 전자 state 표현 수식은 다음과 같다.  \n",
    "\n",
    "    $$수식-(2)$$  \n",
    "    $\\hspace{12mm}$이러한 함수의 복잡성은 실험치를 설명하는 A,B의 조합을 계산하기 어렵게 만든다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fitting을 하면 되지않는가?  \n",
    ": 위와 같은 특징은 Fitting을 위해 hyperfine coefficients(As,Bs)를 변수로 한 loss function을 보면,  \n",
    "$\\hspace{3mm}$A,B에 대한 loss 함수의 local minimum point가 많고 변화도 심하다.  \n",
    "$\\hspace{3mm}$그렇기 때문에 이 함수의 minimum point를 찾을 때 local minimum에 빠지기 쉽다.    \n",
    "$\\hspace{3mm}$무엇보다 fitting을 위한 적절한 initial guess value를 사전에 알기 힘들다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 왜 상온에서는 Decoherence와 Noise가 심한가?  \n",
    ": 상온에서는 저온보다 thermal fluctuation이 크기 때문에, NV center의 전자들의 에너지에 영향을 주기 때문이다.  \n",
    "* 그래서 시도한 방법은 무엇인가?  \n",
    ": Machine Learning 중 Denoise과 Peak Detection을 시도했다.  \n",
    "* 왜 Machine Learning인가?  \n",
    ": Hot 하니까! 하는 이유도 있지만, approximation function을 찾기위해 현재 시도해볼 수 있는 가장 훌륭한 방법이라고 생각했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Machine Learning 방법론은 무엇인가?  \n",
    " : Denoise와 Peak Detection 으로 분리하여 model을 만들었다.  \n",
    " - ============= Denoise 는 한번 확인후 작성 ===============  \n",
    " - peak detection  \n",
    " : 일정 범위의 hyperfine coefficient(A,B)가 있는지 없는지(classification) 판단해주는 Model을 만들었고, 이러한 모델을 여러개 합쳐서,  \n",
    "   보고자하는 A,B 영역을 전부 판별할 수 있도록 만들었다.  \n",
    " : Dense layer, ReLU, Adam, Sigmoid 를 활용하였다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터는 어떻게 만들었는가?  \n",
    ": 데이터는 실험치와 최대한 유사하게 만들었다. 저온(TimTaminiau)과 상온(우리꺼) 실험치와 유사한 데이터 모두를 만들었다.\n",
    "$$[Fig.?]\\;데이터\\;만드는\\; 과정을\\; 도식화.\\; 처음에\\; 만들고\\; --> \\;decoherence\\; -->\\; noise$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전처리는 하였는가?  \n",
    ": 저온 영역에서 우리가 가지고 있는 data point의 개수는 72000개?? 이다. (time resolution: 4ns) (여기는 figure를 넣어도 됨)  \n",
    "이 중에서 처음 12000개가 decoherence가 비교적 작기 때문에 취한 것.  \n",
    "전처리는 Training 속도와 성능 개선을 위해서 필수적이었다.  \n",
    "특정영역의 A,B에 대해서만 판단하면 되므로, 위의 Fig에서 다루었듯, 특정 A,B는 특정한 주기성을 가진다.  \n",
    "그러므로 A,B의 영역을 특정하게 되면, 그 데이터에서 우리가 봐야할 부분은 정해져 있다.  \n",
    "이는 모든 A,B에 대해서 성립하는 특징이며, A,B의 분포가 다르면 봐야할 부분도 다르다.\n",
    "$$[Fig.?]\\; A,B영역마다\\; 다른\\; 곳을\\; 인덱싱하는\\; 그림$$\n",
    "  그 특정영역에 해당하는 부분만 indexing을하여 데이터 생성 및 트레이닝 속도 모두 크게 개선할 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전처리의 구체적인 방법은 어떻게 되는가?  \n",
    ": 특정한 A,B 구간이 정해지면, 특정 영역만 취해도 A,B 판단하는 것에는 큰 문제가 없다.  \n",
    "만일 우리가 원하는 A,B 가 각각 (10000~13000, 20000~25000)이라고 한다면,  \n",
    "  이 영역의 특정한 부분은 다음과 같다.  \n",
    "$$|Fig.?|\\;peak이\\; 있는\\; 상황에서\\; 특정영역만\\;\\; plot한\\; 것. \\;위의\\; fig와\\; 합치자\\;$$\n",
    "따라서 실험치는 12000개이지만, 실제 하나의 모델에 필요한 포인트 개수는 500~700이다. 모델마다 필요한 개수가 상이한 이유는,  \n",
    "각 A,B 영역마다 peak의 feature가 다르기 때문에 필요한 point개수가 다르기 때문이다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 하나의 모델에 대해서 자세히 설명하라. input과 output은 어떻게 되는가?  \n",
    ": 예를 들어, A,B가 각각 (10000~14000, 30000~36000)영역인 모델을 생각해보자.<br/>  \n",
    "그러면 input 데이터는 다음과 같은 영역을 slicing 하여 만든다.(내지는 위의 fig와 합쳐서 설명을 하자) data set은 2종류가 필요하다.  \n",
    "이 영역의 A,B값을 포함하는 data set과 이 영역의 A,B를 포함하지 않는 data set을 만든다.<br/>  \n",
    "그리고 output은 이 data set을 input으로 주었을 때, A,B가 포함하는 data인지 아닌지를 판단하는 sigmoid node를 쓴다.  \n",
    "softmax보다 sigmoid가 다소 좋은 성능을 보여주었기 때문에 sigmoid 를 썼다.  \n",
    "sigmoid의 output을 어떤 값을 기준으로 threshold를 정할지는 휴리스틱하게 정하였다.(관련 참고문헌 적을 것),  \n",
    "이 값은 총 epoch 수, learning rate, val_loss threshold에 따라 각각 다르게 나왔다.<br/>  \n",
    "우리가 이 threshold 를 정한 기준은, 보고자하는 A,B 영역 전부에서 가장 확률분포를 정확하게 맞춘 것을 하였다.\n",
    "$$Fig.??\\; A,B영역을\\; sigmoid \\;threshold마다\\; 다르게\\; 나오는\\; 것을\\; 보여줘도 \\;됨$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* output의 자세한 설명이 필요하다. sigmoid를 썼다고 하는데, 그 값의 구체적인 의미를 밝혀라.  \n",
    ": 예를들어 어떤 모델의 sigmoid output값을 0.9기준으로 있다, 없다를 판단한 후 fitting을 한다.  \n",
    "============= 여기는 어떻게 할지 더 생각해보자 ========================  \n",
    "위와 같은 기준으로 나온 확률이 예를들어 다음과 같이 나왔다면, 이 데이터는 A,B가 (10000~11000, 13000~15000)Hz 사이에 있을  \n",
    "확률이 매우 높게 나온 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그렇게 판단한 후에는 어떻게 하는가?  \n",
    ": 이렇게 A,B가 있을 것이라고 추정되는 범위를 파악한 다음, 이 A,B값을 initial guess로 하여 fine tunning을 한다.\n",
    "$$[Fig.?]\\;Fine\\; Tuning하기\\; 전과\\; 하고\\; 난\\; 후의\\; 그림\\; 비교$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fine tuning은 어떻게 하는가?  \n",
    ": Customized Code를 python으로 작성하였다.  \n",
    "initial guess갑을 기준으로 A,B를 미세하게 변화시켜가면서 실험치와 비교한 MSE가 작은 값을 주는 것을 찾아내는 방식을 택하였다.  \n",
    "여기서는 자기장도 fitting parameter로 들어간다. 왜냐하면 자기장 0.1 gauss도 MSE에 적지않은 영향을 주기때문이다.  \n",
    "자기장 fitting을 할 때의 initial guess값은 실험 setup과정에서 나온 자기장 값을 기반으로 한다.  \n",
    "우리가 사용한 fitting 함수는 python code로 작성하였으며, 다음의 주소에 있다.(github주소 쓸 것)  \n",
    "이렇게 구하면 각 A,B마다 자기장의 fitting 결과가 조금씩 다를 수 있다.  \n",
    "최종적으로는 모든 spin들을 더하여 다시 한번 fine tunning을 하고, 가장 MSE가 작은 자기장을 선택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 왜 모델을 여러개를 합하여 만들었는가? 하나로 만들지 않은이유는 무엇인가?  \n",
    ": 트레이닝 시간을 크게 해치지 않으면서, 성능을 최대한 좋게하기 위해서이다.  \n",
    "성능면에서 하나의 모델보다 각각의 영역을 나누어 여러개의 모델을 만드는 것이 더 좋기 때문이다.<br/><br/>\n",
    "예를 들어 12000point전부에 대해서 하게 되면, 예컨데 A,B가 (10000~12000, 13000~16000)구간의 spin을 판별하는 모델을 짜게되면,  \n",
    "1번째 layer의 weight분포는 다음과 같이 나온다. spin의 실제 패턴과 유사한 패턴을 보임을 알 수 있다. 매우 놀라운 결과이지만,  \n",
    "동시에 다른 node의 값은 거의 0인 값(die)을 보여주고 있다.<br/><br/>\n",
    "따라서 하나를 판별하는 것은 부분적인 것만 보는것이 훨씬 효율적이고 성능을 해치지 않을 것을 짐작할 수 있다.  \n",
    "만일 하나의 모델일 여러개를 동시에 데이터를 만드는 개수와 output node의 개수가 크게 늘어나게 되어 역시 computational cost가 크게 상승한다.<br/><br/>\n",
    "이러한 이유로 여러개를 만들면 트레이닝 시간이 오래걸리는 것이 일반적이지만, \n",
    "우리의 경우에는 오히려 data slicing등을 적용할 수 있게 되어, 트레이닝 시간을 더 획기적으로 줄일 수 있었다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다른 Hyperfine 을 찾는 실험과 어떻게 다른가?  \n",
    ": 다른 실험에서는 Strong Peak을 CPMG 데이터에서는 찾지못하였지만, 우리실험에서는 Strong Peak도 매우정확하게 찾을 수 있다.  \n",
    "또한 다른 실험에서 찾지 못한 작은 Spin들도 찾은 경우가 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 Preparation에 대해서 상세하게 기술하라. output에 sigmoid를 활용하였다고 하였는데, 몇 개의 node를 썼는가?  \n",
    "  그리고 input data의 small spin에 대한 경우는 어떻게 만들었는지 상세히 기술하라.  \n",
    "  : sigmoid 함수의 output은 총 10개(9월9일까지의 최신 모델)이고, 각 node는 heatmap의 각 1칸씩 총 3개, 그리고 2개가 동시에 있을 경우에 6개, 어디에도 없는 경우에 1개.  \n",
    "  즉, 총 10개의 output node가 있고, y label은 one hot encoding으로 하였다.  \n",
    "  --> 그러나 다시 바꾸어보려고 한다(9/9) --> one hot encoding이 아니라, multi label로 하여 2개가 있는 경우를 구할 수 있도록 해보려 한다.  \n",
    "  --> 무엇보다 또한 B뿐만 아니라 A도 2~3개 폭을 가지도록 데이터를 만들어 보려고 한다.\n",
    "  \n",
    "  input data에서, 특히 small spin에 대해서는 다시 만들어야 한다. 왜냐하면, decoherence 때문에 spin의 효과가 너무 묻혀버리기 떄문이다. 결국 denoise를 해서 slope을 곱하는  \n",
    "  방식을 취할 수 밖에 없을 것 같다.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=== 마지막에는 여러가지 시뮬레이션 데이터를넣고 실험해보고,  \n",
    "    마찬가지로 실험치도 여러게 넣고 해봐야함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=== 우리는 네트워크가 실제로 주기성을 판단하여, spin유무를 판단한다는 것을 보았다(Supplementry 그림으로 weight of 1-hiddel layer)  \n",
    "이러한 결과는 network이 cpmg data에서 스스로 주기성을 파악하여 spin 유무를 학습한다는 점을 시사한다.    \n",
    "이러한 점은, 특정 peak이 나오는 부분(즉, 주기적인 indexing)만 취하여 학습을 시켰을 때의 성능비교를 해보았을 때 두드러지게 나타난다.  \n",
    "실제로 다음은 그 차이가 크지 않음을 보여준다.(여기에 S1 table이 들어가야 함)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
